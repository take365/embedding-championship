import os
import pickle
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from pathlib import Path
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.cluster import KMeans
import math
import argparse
from config_models import MODELS
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®æŒ‡å®š
rcParams['font.family'] = 'Meiryo' 


def load_umap_embeddings(path):
    with open(path, "rb") as f:
        return pickle.load(f)

def evaluate_model(X, k_range):
    silhouette, dbi, chi, wcss = [], [], [], []
    for k in k_range:
        km = KMeans(n_clusters=k, random_state=42, n_init='auto').fit(X)
        labels = km.labels_
        silhouette.append(silhouette_score(X, labels))
        dbi.append(davies_bouldin_score(X, labels))
        chi.append(calinski_harabasz_score(X, labels))
        wcss.append(km.inertia_)
    return silhouette, dbi, chi, wcss

def plot_comparison(metric_values, title, ylabel, filename, k_range,output_dir):
    plt.figure(figsize=(10, 6))
    for key, values in metric_values.items():
        plt.plot(k_range, values, label=key)

    base_k = math.sqrt(len(k_range) * 2)
    lower_threshold = round(base_k * 2)
    plt.axvline(x=lower_threshold, color='gray', linestyle='--', linewidth=1)
    plt.text(lower_threshold + 0.5, plt.ylim()[1]*0.9, 'ä¸‹ä½å±¤é–‹å§‹', rotation=90, color='gray')

    plt.xlabel("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (k)")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.savefig(output_dir / filename)
    plt.close()
def suggest_cluster_range(n_samples: int, level: str) -> range:
    base_k = math.sqrt(n_samples / 2)

    if level == "all":
        # å…¨ä½“è©•ä¾¡ç”¨ï¼šãŸã¨ãˆã° k=2ã€œ4å€ã¾ã§åºƒãã‚«ãƒãƒ¼
        return range(round(base_k / 4), round(base_k * 4) + 1)
    elif level == "upper":
        return range(round(base_k / 4), round(base_k * 2) - 1)
    elif level == "lower":
        return range(round(base_k * 2), round(base_k * 4) + 1)
    else:
        raise ValueError("level must be 'all', 'upper' or 'lower'")
    
def generate_html_report(metrics, k_range,data_dir,output_dir):
    html = ["<html><head><meta charset='utf-8'><title>ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ</title></head><body>"]

    title_path = data_dir / "title.txt"
    title = title_path.read_text(encoding="utf-8").strip() if title_path.exists() else "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«æœªè¨­å®šï¼‰"
    data_count = 0
    for key in metrics:
        df_path = data_dir / f"{key}.pkl"
        if df_path.exists():
            df = pd.read_pickle(df_path)
            data_count = len(df)
            break
    html.append(f"<h1>{title}ï¼ˆ{data_count}ä»¶ï¼‰</h1>")

    base_k = math.sqrt(data_count / 2)
    lower_start = round(base_k * 2)

    model_keys = list(metrics.keys())

    def explanation(metric):
        if metric == "silhouette":
            return ("<p>ã‚¯ãƒ©ã‚¹ã‚¿å†…ã¨ä»–ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®è·é›¢ã®æ¯”è¼ƒã«åŸºã¥ãæŒ‡æ¨™ã§ã€-1ã‹ã‚‰+1ã®ç¯„å›²ã®ã‚¹ã‚³ã‚¢ã‚’æŒã¡ã¾ã™ã€‚"
                    "<b>ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ã«ã‚¯ãƒ©ã‚¹ã‚¿ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹</b>ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚"
                    "<a href='https://en.wikipedia.org/wiki/Silhouette_(clustering)' target='_blank'>[Wikipedia]</a></p>")
        elif metric == "dbi":
            return ("<p>å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ã°ã‚‰ã¤ãã¨ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®è·é›¢æ¯”ã‚’ã‚‚ã¨ã«è¨ˆç®—ã•ã‚Œã‚‹æŒ‡æ¨™ã§ã€"
                    "<b>ã‚¹ã‚³ã‚¢ã¯å°ã•ã„ã»ã©ã‚¯ãƒ©ã‚¹ã‚¿ãŒå¯†é›†ã‹ã¤æ˜ç¢ºã«åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹</b>ã¨ã•ã‚Œã¾ã™ã€‚"
                    "<a href='https://en.wikipedia.org/wiki/Davies%E2%80%93Bouldin_index' target='_blank'>[Wikipedia]</a></p>")
        elif metric == "chi":
            return ("<p>ã‚¯ãƒ©ã‚¹ã‚¿å†…åˆ†æ•£ã¨ã‚¯ãƒ©ã‚¹ã‚¿é–“åˆ†æ•£ã®æ¯”ç‡ã‹ã‚‰ãªã‚‹æŒ‡æ¨™ã§ã™ã€‚"
                    "<b>å€¤ãŒå¤§ãã„ã»ã©ã‚¯ãƒ©ã‚¹ã‚¿ã®åˆ†é›¢ãŒè‰¯å¥½</b>ã¨ã•ã‚Œã¾ã™ã€‚"
                    "<a href='https://en.wikipedia.org/wiki/Calinski%E2%80%93Harabasz_index' target='_blank'>[Wikipedia]</a></p>")
        elif metric == "wcss":
            return ("<p>ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®ã°ã‚‰ã¤ãï¼ˆå„ç‚¹ã¨é‡å¿ƒã®è·é›¢ã®äºŒä¹—å’Œï¼‰ã‚’ç¤ºã™æŒ‡æ¨™ã§ã€"
                    "<b>ã‚¹ã‚³ã‚¢ãŒå°ã•ã„ã»ã©ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®å‡é›†æ€§ãŒé«˜ã„</b>ã¨ã•ã‚Œã¾ã™ã€‚"
                    "<br>ã“ã®æŒ‡æ¨™ã‚’ç”¨ã„ãŸã‚¨ãƒ«ãƒœãƒ¼æ³•ã«ã‚ˆã‚Šã€æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’è¦–è¦šçš„ã«æ±ºå®šã§ãã¾ã™ã€‚"
                    "<a href='https://en.wikipedia.org/wiki/Elbow_method_(clustering)' target='_blank'>[Elbow Method]</a></p>")
        return ""

    for metric in ["silhouette", "dbi", "chi", "wcss"]:
        html.append(f"<h2>{metric.upper()} æ¯”è¼ƒ</h2>")
        html.append(explanation(metric))
        if metric == "silhouette":
            # ãƒ¢ãƒ‡ãƒ«é †ã®ä¸¦ã³ï¼ˆä¿æŒã—ãŸé †ã§å®‰å®šåŒ–ï¼‰
            model_keys = list(MODELS.keys())

            html.append("<h3>ç·åˆè©•ä¾¡</h3>")
            html.append("<table border='1'>")

            # è¦‹å‡ºã—è¡Œï¼ˆãƒ¢ãƒ‡ãƒ«åï¼‰
            header_row_1 = "<tr><th></th>"
            for key in model_keys:
                model_name = MODELS[key]["model_id"]
                header_row_1 += f"<th colspan='2'>{model_name}</th>"
            header_row_1 += "</tr>"
            html.append(header_row_1)

            # è¦‹å‡ºã—è¡Œ2ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿æ•°ã€ã‚¹ã‚³ã‚¢ã€æ³¨é‡ˆï¼‰
            header_row_2 = "<tr><th>ç¨®åˆ¥</th>"
            for _ in model_keys:
                header_row_2 += "<th>ã‚¯ãƒ©ã‚¹ã‚¿æ•°</th><th>ã‚¹ã‚³ã‚¢</th>"
            header_row_2 += "</tr>"
            html.append(header_row_2)

            # è¡Œãƒ‡ãƒ¼ã‚¿ã‚’3æ®µã¾ã¨ã‚ã¦å‡ºã™ï¼ˆå…¨ä½“ãƒ»ä¸Šä½å±¤ãƒ»ä¸‹ä½å±¤ï¼‰
            row_types = ["å…¨ä½“", "ä¸Šä½å±¤", "ä¸‹ä½å±¤"]
            for row_type in row_types:
                row_html = f"<tr><td>{row_type}</td>"
                for key in model_keys:
                    scores = metrics[key]["silhouette"]
                    k_values = list(k_range)

                    # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
                    df_path = data_dir / f"{key}.pkl"
                    df = pd.read_pickle(df_path)
                    local_data_count = len(df)

                    # å„ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®æ­£ã—ã„ç¯„å›²ã‚’å–å¾—ï¼ˆã“ã“ãŒé‡è¦ãªä¿®æ­£ç‚¹ï¼‰
                    upper_k_range = suggest_cluster_range(local_data_count, "upper")
                    lower_k_range = suggest_cluster_range(local_data_count, "lower")
                    # å…¨ä½“ã®ãƒ™ã‚¹ãƒˆï¼ˆå…¨ç¯„å›²ï¼‰
                    all_k_best = max(zip(k_values, scores), key=lambda x: x[1])

                    # ä¸Šä½å±¤ã ã‘ã«çµã£ãŸã‚¹ã‚³ã‚¢ç¾¤
                    upper_scores = [(k, s) for k, s in zip(k_values, scores) if k in upper_k_range]
                    lower_scores = [(k, s) for k, s in zip(k_values, scores) if k in lower_k_range]

                    if row_type == "å…¨ä½“":
                        k_best, score = all_k_best
                    elif row_type == "ä¸Šä½å±¤":
                        k_best, score = max(upper_scores, key=lambda x: x[1]) if upper_scores else ("-", 0)
                    elif row_type == "ä¸‹ä½å±¤":
                        k_best, score = max(lower_scores, key=lambda x: x[1]) if lower_scores else ("-", 0)

                    row_html += f"<td>{k_best}</td><td>{f'{score:.3f}' if isinstance(score, (int, float)) else score}</td>"
                row_html += "</tr>"
                html.append(row_html)

            html.append("</table><br>")

        html.append("<table><tr>")
        html.append(f"<td valign='top'><img src='{metric}_compare.png' width='800'></td>")
        html.append("<td><table border='1'>")

        max_scores = {key: max(metrics[key][metric]) for key in MODELS}
        min_scores = {key: min(metrics[key][metric]) for key in MODELS} if metric in ["dbi", "wcss"] else {}

        if metric == "silhouette":
            html.append("<tr><th>ã‚¯ãƒ©ã‚¹ã‚¿æ•°</th>")
            for key in MODELS:
                html.append(f"<th>{key} ã‚¹ã‚³ã‚¢</th><th>{key} è£œè¶³</th>")
            html.append("</tr>")

            annot_maps = {}
            for key in MODELS:
                scores = metrics[key][metric]
                annot_map = {}
                best_value = -float("inf")
                best_k = None
                for idx_i, k_i in enumerate(k_range):
                    current = scores[idx_i]
                    if current > best_value:
                        best_value = current
                        best_k = k_i
                    last_j = None
                    for idx_j in range(idx_i + 1, len(k_range)):
                        comp = scores[idx_j]
                        k_j = list(k_range)[idx_j]
                        if current > comp:
                            last_j = k_j
                            continue
                        else:
                            break
                    if last_j is not None and k_i == best_k:
                        annot_map[k_i] = last_j
                annot_maps[key] = annot_map

            for i, k in enumerate(k_range):
                if k == lower_start:
                    colspan = 1 + len(MODELS) * (2 if metric == "silhouette" else 1)
                    html.append(f"<tr><td colspan='{colspan}' style='text-align:center; font-weight:bold;'>â–¼ ä¸‹ä½å±¤ â–¼</td></tr>")
    
                row = f"<tr><td>{k}</td>"
                for key in MODELS:
                    score = metrics[key][metric][i]
                    note = ""
                    style = ""
                    if score == max_scores[key]:
                        style = " style='background-color:#90ee90'"
                        note = "æœ€é«˜å€¤"
                    else:
                        if k in annot_maps[key]:
                            style = " style='background-color:#e0ffe0'"
                            note = f"kâ‰¦{annot_maps[key][k]}ã§æœ€é«˜"
                    row += f"<td{style}>{f'{score:.3f}'}</td><td>{note}</td>"
                row += "</tr>"
                html.append(row)
        else:
            html.append("<tr><th>ã‚¯ãƒ©ã‚¹ã‚¿æ•°</th>")
            for key in MODELS:
                html.append(f"<th>{key}</th>")
            html.append("</tr>")
            for i, k in enumerate(k_range):
                row = f"<tr><td>{k}</td>"
                for key in MODELS:
                    val = metrics[key][metric][i]
                    if metric in ["dbi", "wcss"]:
                        style = " style='background-color:#90ee90'" if val == min_scores[key] else ""
                    else:
                        style = " style='background-color:#90ee90'" if val == max_scores[key] else ""
                    row += f"<td{style}>{f'{val:.3f}'}</td>"
                row += "</tr>"
                html.append(row)


        html.append("</table></td></tr></table><br>")
    html.append("<p>ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®ç¯„å›²ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ï¼š</p>"
                "<ul>"
                "<li><b>ä¸Šä½å±¤ï¼š</b> âˆš(n/2) ã® 1/4å€ ï½ 4å€</li>"
                "<li><b>ä¸‹ä½å±¤ï¼š</b> âˆš(n/2) ã® 2å€ ï½ 4å€</li>"
                "</ul>"
                "<p>ã“ã“ã§ n ã¯æ„è¦‹æ•°ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ï¼‰ã§ã™ã€‚</p>")

    html.append("</body></html>")

    with open(output_dir / "compare_models.html", "w", encoding="utf-8") as f:
        f.write("\n".join(html))

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("dataset", help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆä¾‹: pubene, pubkanï¼‰")
    args = parser.parse_args()

    data_dir = Path(f"inputs/{args.dataset}")
    # === è¨­å®š ===
    output_dir = Path(f"outputs/{args.dataset}")
    output_dir.mkdir(exist_ok=True)

    all_metrics = {}
    any_path = next((data_dir / f"{key}_umap.pkl" for key in MODELS if (data_dir / f"{key}_umap.pkl").exists()), None)
    if not any_path:
        raise RuntimeError("UMAPæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    df = pd.read_pickle(any_path)
    n_samples = len(df)
    k_range = suggest_cluster_range(n_samples, "all")

    for key in MODELS:
        path = data_dir / f"{key}_umap.pkl"
        if not path.exists():
            print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {key}_umap.pkl ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            continue

        print(f"ğŸ“Š Evaluating {key}...")
        X = load_umap_embeddings(path)
        sil, dbi, chi, wcss = evaluate_model(X, k_range)
        all_metrics[key] = {
            "silhouette": sil,
            "dbi": dbi,
            "chi": chi,
            "wcss": wcss
        }
    for metric in ["silhouette", "dbi", "chi", "wcss"]:
        metric_data = {key: all_metrics[key][metric] for key in all_metrics}
        ylabel = metric.upper()
        plot_comparison(metric_data, f"{metric.upper()} Comparison", ylabel, f"{metric}_compare.png", k_range, output_dir)

    generate_html_report(all_metrics, k_range, data_dir, output_dir)
    print("âœ… ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚°ãƒ©ãƒ•å‡ºåŠ›å®Œäº†")

if __name__ == "__main__":
    main()
